{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "EOF read where object expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/eind_opdracht/examen-22/notebooks/02_style_detection.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d7644696a6b48554d4c227d/home/mladmin/code/eind_opdracht/examen-22/notebooks/02_style_detection.ipynb#ch0000000vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_tools\u001b[39;00m \u001b[39mimport\u001b[39;00m StyleDataset\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d7644696a6b48554d4c227d/home/mladmin/code/eind_opdracht/examen-22/notebooks/02_style_detection.ipynb#ch0000000vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d7644696a6b48554d4c227d/home/mladmin/code/eind_opdracht/examen-22/notebooks/02_style_detection.ipynb#ch0000000vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-Z0MsbPIA-py3.9/lib/python3.9/site-packages/seaborn/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrcmod\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpalettes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-Z0MsbPIA-py3.9/lib/python3.9/site-packages/seaborn/rcmod.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcycler\u001b[39;00m \u001b[39mimport\u001b[39;00m cycler\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m palettes\n\u001b[1;32m     10\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mset_theme\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreset_defaults\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreset_orig\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39maxes_style\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_style\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mplotting_context\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_context\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mset_palette\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m _style_keys \u001b[39m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maxes.facecolor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m ]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-Z0MsbPIA-py3.9/lib/python3.9/site-packages/seaborn/palettes.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternal\u001b[39;00m \u001b[39mimport\u001b[39;00m husl\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m desaturate, get_color_cycle\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m xkcd_rgb, crayons\n\u001b[1;32m     13\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcolor_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhls_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhusl_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmpl_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mdark_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlight_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdiverging_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mblend_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxkcd_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcrayon_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mcubehelix_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_color_codes\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m SEABORN_PALETTES \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     20\u001b[0m     deep\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m#4C72B0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#DD8452\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#55A868\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#C44E52\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#8172B3\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m#937860\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#DA8BC3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#8C8C8C\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#CCB974\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#64B5CD\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39m#CC78BC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#ECE133\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#56B4E9\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-Z0MsbPIA-py3.9/lib/python3.9/site-packages/seaborn/colors/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mxkcd_rgb\u001b[39;00m \u001b[39mimport\u001b[39;00m xkcd_rgb  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcrayons\u001b[39;00m \u001b[39mimport\u001b[39;00m crayons\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:978\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:647\u001b[0m, in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: EOF read where object expected"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 06:58:01.801 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'humor': 4213, 'reuters': 4186, 'wiki': 4181, 'proverbs': 831}\n",
      "{'humor': 31.414510476474533, 'reuters': 31.21318320781448, 'wiki': 31.175900380284844, 'proverbs': 6.196405935426143}\n"
     ]
    }
   ],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "label_dict = {\n",
    "    \"humor\": 0,\n",
    "    \"reuters\": 0,\n",
    "    \"wiki\": 0,\n",
    "    \"proverbs\": 0\n",
    "}\n",
    "\n",
    "for row in traindataset.dataset:\n",
    "    label_dict[row[1]] += 1\n",
    "\n",
    "print(label_dict)\n",
    "\n",
    "for k in label_dict:\n",
    "    label_dict[k] =  label_dict[k] / len(traindataset.dataset) * 100\n",
    "\n",
    "print(label_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 25]),\n",
       " tensor([2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 0, 2, 1, 2, 0, 0,\n",
       "         1, 1, 1, 0, 0, 1, 1, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = None\n",
    "loss_fn = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "model = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=1,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-Z0MsbPIA-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abd276725262becaa5c3e256f8c38384c11f1a26b31876c2a00eb7476ce26550"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
