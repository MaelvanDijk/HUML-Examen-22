{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 18:25:31.485405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 18:25:31.485460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.data import make_dataset, data_tools\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from src.settings import EurosatSettings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Download data\n",
    "This will take about 30 minutes\n",
    "While waiting, read about the dataset we are using on their [github](https://github.com/phelber/eurosat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = EurosatSettings()\n",
    "data_dir = settings.data_dir\n",
    "# datapath = make_dataset.get_eurosat(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all valid paths. The files are images in .tif format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_paths = data_dir / settings.valid_paths\n",
    "all_paths, _ = data_tools.iter_valid_paths(valid_paths, formats=[\".tif\"])\n",
    "all_paths = [*all_paths]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the files with `tifffile.imread(\"path/to/img.tif\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13 ms ± 25.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.15675245694416"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadtime = %timeit -o tifffile.imread(all_paths[1])\n",
    "loadtime.average * 2 * 32 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, loading a tifffile is pretty fast. I clock 1.24 ms per image. This means that you expect the loader to take at least 1.24 x 4 images x batchsize x 1000 milliseconds, which is around 160ms. \n",
    "\n",
    "If your dataloader would take much more time than that (e.g. 500 ms per batch) you are doing something inefficient in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 motivation: Siamese networks\n",
    "<img src=\"https://929687.smushcdn.com/2633864/wp-content/uploads/2020/11/keras_siamese_networks_header.png?lossy=1&strip=1&webp=1\" />\n",
    "\n",
    "We will build a dataloader for a Siamese network.\n",
    "This is a semi-unsupervised architecture. It:\n",
    "- takes in *two* images instead of one\n",
    "- every image is processed by the *same* model (e.g. a CNN)\n",
    "- the output of the model is a vector. Your input is (batch, channels, width, height) and the output is (batch, dimensions). Think of the vectors as locations in a space. E.g. you can locate Utrecht with two dimenions: (52.0929, 5.1045) on the globe (latitude, longitude). This is the same idea, only here the vector has more than 2 dimensions.\n",
    "- after this, you can compare the *distance* between the two vectors.\n",
    "- The distance should be close if the images are the same, or far away if they are not.\n",
    "\n",
    "# 3 Datastructure\n",
    "We will not build a siamese network, just the dataloader.\n",
    "This means we will need a dataloader that spits out:\n",
    "(X1, X2, y)  instead of our usual (X, y).\n",
    "\n",
    "The label y will be: 1 if the two images are from the same class, 0 otherwise.\n",
    "\n",
    "The most naive approach would be something like is implemented [here](https://datahacker.rs/019-siamese-network-in-pytorch-with-application-to-face-similarity): to get the same class, you just keep on loading images at random in a while loop untill you hit the same class by accident... \n",
    "\n",
    "I hope you can understand why this is a *horrible* idea in terms of efficiency!\n",
    "And another reason to be very carefull to implement random code from the internet...\n",
    "\n",
    "To spell out why: with 10 classes (or, even worse, 40 classes in the example link) you will pick every class with a chance $p=\\frac{1}{10}$ (or $p=\\frac{1}{40}$). So the chance you *dont* pick the same class is $(1-p)$. You would have to do about 6 random picks to get close to a 50% chance of picking the same class ($0.9^6=0.53$), and even up to 26 guesses with 40 classes ($0.975^{26}=0.51$). This is a horrible waste of resources. You will end up spending a big chunk of your time loading random images, and it scales absolutely horrific with more classes (try to calculate how often you need to guess with 100 classes, or 150...) So, can we do better?\n",
    "\n",
    "We will use a different datastructure to do this in a proper way! No worries, I will help you along the way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a datastructure, we will need something where we easily can pull two images from the same class. To do this, we will make a `Dict[int, np.array]` where the numpy array is an array of paths.\n",
    "\n",
    "We use the np.array instead of the list, in order to be able to quickly grab two random items from the array with an integer index.\n",
    "\n",
    "A dummy example is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = {\n",
    "    0: np.array([\"path/to/a/01.jpg\", \"path/to/a/02.jpg\"]),\n",
    "    1: np.array([\"path/to/b/03.jpg\", \"path/to/b/04.jpg\"]),\n",
    "    2: np.array([\"path/to/c/05.jpg\", \"path/to/c/06.jpg\", \"path/to/c/07.jpg\"]),\n",
    "}\n",
    "\n",
    "[len(v) for k, v in dummy.items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see we have three classed (a, b and c), that are in the dictionary as class 0, 1, and 2, and every class has two or three images listed (to be exact with the last line of code: 2, 2, and 3).\n",
    "\n",
    "In addition to this, we want our dataset to have a name_mapping that is a `Dict[str, int]` which maps from the names to an integer. In our case this will be\n",
    "\n",
    "```python\n",
    "name_mapping = {\n",
    "    \"a\" : 0,\n",
    "    \"b\" : 1,\n",
    "    \"c\" : 2\n",
    "}\n",
    "```\n",
    "\n",
    "If we need two images from class 2, we can create a random index [0, 2] and the code example below will give us two images (the 0th and the 2nd) that are from the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['path/to/c/05.jpg', 'path/to/c/07.jpg'], dtype='<U16')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classlabel = 2\n",
    "idx = np.array([0, 2])\n",
    "dummy[classlabel][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "We want to implement `EuroSatDataset`, which inherits from `BaseDataset`.\n",
    "### Implement `__len__`\n",
    "in the example above, the lenght of the dataset is 2+2+3=7.\n",
    "The lengths of the dataset is the count of all paths in all classes.\n",
    "\n",
    "Implement the `__len__` method in the EuroSatDataset in data_tools.py so that it returns the correct lenght of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, Iterator, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "# import tifffile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.typehinting import DictDataset, ListDataset\n",
    "from src.data.data_tools import BaseDictDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuroSatDataset(BaseDictDataset):\n",
    "    def __init__(self, paths: List[Path]) -> None:\n",
    "        \"\"\"\n",
    "        This dataset is stored as a dictionary instead of a list.\n",
    "        The dictionary stores int : List[Path] key-value pairs\n",
    "        the key is a class, the value is a list of paths of an identical class\n",
    "        eg:\n",
    "\n",
    "        dataset = {\n",
    "            0 : [\"path/to/a/01.jpg\", \"path/to/a/02.jpg\"],\n",
    "            1 : [\"path/to/b/03.jpg\", \"path/to/b/04.jpg\"]\n",
    "        }\n",
    "\n",
    "        Args:\n",
    "            paths (List[Path]): filepaths, where the class name is the parent folder\n",
    "        \"\"\"\n",
    "        super().__init__(paths)\n",
    "        self.paths = paths\n",
    "        self.name_mapping = []\n",
    "        classes_set = set()\n",
    "        for path in all_paths:\n",
    "            cur_class = str(path)\n",
    "            cur_class = cur_class.split('/')[-2]\n",
    "            classes_set.add(cur_class)\n",
    "\n",
    "        self.name_mapping = dict(zip(classes_set, range(len(classes_set))))\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        for path in tqdm(self.paths):\n",
    "            class_name = path.parent.name\n",
    "            if class_name not in self.name_mapping:\n",
    "                self.name_mapping[class_name] = len(self.name_mapping)\n",
    "\n",
    "            # add key-value pairs to self.dataset\n",
    "            # the key is the class integer from name_mapping,\n",
    "            # the value is the current List of Paths\n",
    "            # if there is no value for the key, return an empty List\n",
    "            # TODO ~ finish these 2 lines of code below\n",
    "            key: int = self.name_mapping[class_name]\n",
    "            value: np.ndarray = self.dataset.get(key, np.array([]))\n",
    "            \n",
    "            # we append the new path to the values we already had\n",
    "            self.dataset[key] = np.append(value, np.array([path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27000/27000 [00:00<00:00, 35393.44it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = EuroSatDataset(all_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### implement process_data\n",
    "\n",
    "Finish `process_data`. You need to fill the dataset dict structure.\n",
    "To do this, you need to map a key (which is an integer: the label mapped to an int).\n",
    "In our example, the label \"a\" should be stored as key 0. Use `name_mapping` for that:\n",
    "\n",
    "```python\n",
    "name_mapping[\"a\"]\n",
    "```\n",
    "\n",
    "will return the correct integer we can use as a key.\n",
    "\n",
    "You also need to store the values: paths in an np.array. \n",
    "To do this, we will start with an empty np.array, and keep appending new paths to this array.\n",
    "While that is not an ideal thing to do, we only need to do this once so it is acceptable.\n",
    "\n",
    "The endresult of `process_data` should be, that the input `all_paths` is transformed into a Dict[int, np.array] dataset, just like the dummy example below.\n",
    "\n",
    "```python\n",
    "dummy = {\n",
    "    0: np.array([\"path/to/a/01.jpg\", \"path/to/a/02.jpg\"]),\n",
    "    1: np.array([\"path/to/b/03.jpg\", \"path/to/b/04.jpg\"]),\n",
    "    2: np.array([\"path/to/c/05.jpg\", \"path/to/c/06.jpg\", \"path/to/c/07.jpg\"]),\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabel = 2\n",
    "idx = np.array([0, 2])\n",
    "dummy[classlabel][idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "eurosat = data_tools.EuroSatDataset(paths=all_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(k) for k,v in eurosat.dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat.dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = eurosat.dataset\n",
    "[len(v) for k, v in dataset.items()], eurosat.name_mapping, len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "## implement batchloop\n",
    "\n",
    "It is not straightforward to implement a mechanism that picks two random images from the same class, and two random images from different classes, and do so at speed.\n",
    "I made an implementation to help you on the way.\n",
    "\n",
    "My implementation is fast enough, but if you dont want to use it you can implement it in another way for yourself.\n",
    "\n",
    "The endresult should be the same, however:\n",
    "- fill a batch with 50% similar images from the same class with label 1 (x1, x2, 1) and 50% images with different classes with label 0 (x1, x2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My random_index() function returns five items. The first two are:\n",
    "- equal (int): this is a random class key from which to pick similar images\n",
    "- same (List[np.array]) : this is a list of indexes. You can use an index to get two images from the class \n",
    "\n",
    "A working example with the dummy data is like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = 2 # from class two\n",
    "same = [np.array([0, 1]), np.array([0, 2])] # we can pick these two combos\n",
    "idx = same[0] # we use the first one of the combos\n",
    "x1, x2 = dummy[equal][idx] # and retrieve from class 2 the paths on index 0 and 1\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this selects images from class number 2 (`equal`)\n",
    "The images selected are the 0th and 1th (`same[0]`).\n",
    "The result is two paths, both in class \"c\" (which is the 2nd class).\n",
    "\n",
    "The other 3 items random_index() returns are:\n",
    "- i and j. Two different class keys \n",
    "- other. A list of tuples, every tuple contains two indexes, one from class i, one from class j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # the first class we will pick from\n",
    "j = 2 # the second class we will pick from\n",
    "other = [(0, 0), (0, 2), (1, 2)] # these are the possible path indeces\n",
    "\n",
    "idx = other[0] # we take the first combo\n",
    "x1, x2 = dummy[i][idx[0]], dummy[j][idx[1]] \n",
    "# and extract from class i the 0th path (idx[0]),\n",
    "# and from class j also the 0th path (idx[1]))\n",
    "x1, x2 # this gives us two paths, from different classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even though the two indexes in `other` are both 0, one of them is pulled from class i, the other from class j.\n",
    "We end up with two different paths from class \"a\" and class \"c\".\n",
    "\n",
    "Implement this mechanism in SiameseStreamer.batchloop()\n",
    "\n",
    "## Tests\n",
    "You can run these tests to see if everything works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eurosat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = data_tools.SiameseStreamer(\n",
    "    dataset=eurosat,\n",
    "    batchsize=32,\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit x1, x2, y = next(streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_tif(img):\n",
    "    img_ = img[..., [1, 2, 3]]\n",
    "    x = img_.astype(np.int32)\n",
    "    x = x / x.max()\n",
    "    return x\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "axs = axs.ravel()\n",
    "for i in range(9):\n",
    "    img1, img2, y = next(streamer)\n",
    "    x = show_tif(img1[0])\n",
    "    axs[i].imshow(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-Z0MsbPIA-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abd276725262becaa5c3e256f8c38384c11f1a26b31876c2a00eb7476ce26550"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
